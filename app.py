import streamlit as st
from openai import OpenAI
import PyPDF2
from docx import Document
from pptx import Presentation
import pandas as pd
from PIL import Image
import pytesseract
import speech_recognition as sr
from pydub import AudioSegment
import io
import os

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="DSE å…¨èƒ½æ¸©ç¿’å¹³å°", layout="wide", page_icon="ğŸ‡­ğŸ‡°")

# --- 2. å®‰å…¨è®€å– API Key ---
api_key = None
if "DEEPSEEK_API_KEY" in st.secrets:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
else:
    api_key = st.sidebar.text_input("DeepSeek API Key", type="password")

if not api_key:
    st.warning("âš ï¸ è«‹è¨­å®š API Key ä»¥ç¹¼çºŒã€‚")
    st.stop()

client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

# --- 3. æ ¸å¿ƒåŠŸèƒ½ï¼šè¬èƒ½æª”æ¡ˆè®€å–å™¨ ---
def extract_text_from_file(uploaded_file):
    text = ""
    file_type = uploaded_file.name.split('.')[-1].lower()
    
    try:
        # A. è™•ç† PDF
        if file_type == 'pdf':
            reader = PyPDF2.PdfReader(uploaded_file)
            for page in reader.pages:
                text += page.extract_text() + "\n"
                
        # B. è™•ç† Word
        elif file_type == 'docx':
            doc = Document(uploaded_file)
            for para in doc.paragraphs:
                text += para.text + "\n"
                
        # C. è™•ç† PowerPoint
        elif file_type == 'pptx':
            prs = Presentation(uploaded_file)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
        
        # D. è™•ç† Excel / CSV (è½‰æ›ç‚º Markdown è¡¨æ ¼)
        elif file_type in ['xlsx', 'xls', 'csv']:
            if file_type == 'csv':
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            # å°‡è¡¨æ ¼è½‰ç‚ºæ–‡å­—æ ¼å¼ï¼Œè®“ AI è®€æ‡‚
            text = df.to_markdown(index=False)

        # E. è™•ç† åœ–ç‰‡ (OCR)
        elif file_type in ['jpg', 'jpeg', 'png']:
            image = Image.open(uploaded_file)
            # ä½¿ç”¨ Tesseract é€²è¡Œ OCRï¼Œè¨­å®šç¹é«”ä¸­æ–‡+è‹±æ–‡
            # æ³¨æ„ï¼šStreamlit Cloud éœ€é€é packages.txt å®‰è£ tesseract
            text = pytesseract.image_to_string(image, lang='chi_tra+eng')
            if not text.strip():
                text = "[OCR æç¤º] åœ–ç‰‡ä¸­æœªèƒ½è­˜åˆ¥å‡ºæ–‡å­—ï¼Œè«‹ç¢ºä¿åœ–ç‰‡æ¸…æ™°ã€‚"

        # F. è™•ç† è²éŸ³ (Speech to Text)
        elif file_type in ['mp3', 'wav', 'm4a']:
            # è½‰æ›éŸ³è¨Šæ ¼å¼ç‚º wav (SpeechRecognition éœ€è¦ wav)
            audio = AudioSegment.from_file(uploaded_file)
            wav_buffer = io.BytesIO()
            audio.export(wav_buffer, format="wav")
            wav_buffer.seek(0)
            
            recognizer = sr.Recognizer()
            with sr.AudioFile(wav_buffer) as source:
                audio_data = recognizer.record(source)
                # ä½¿ç”¨ Google å…è²» API è­˜åˆ¥ (æ”¯æ´å»£æ±è©±/ç¹ä¸­)
                # å»£æ±è©± code: yue-Hant-HK, åœ‹èª: cmn-Hant-TW
                try:
                    text = recognizer.recognize_google(audio_data, language="yue-Hant-HK")
                except sr.UnknownValueError:
                    text = "[Audio æç¤º] ç„¡æ³•è­˜åˆ¥èªéŸ³ï¼Œå¯èƒ½æ˜¯è²éŸ³å¤ªå°æˆ–é›œè¨Šéå¤šã€‚"
                except sr.RequestError:
                    text = "[Audio æç¤º] èªéŸ³è­˜åˆ¥æœå‹™æš«æ™‚ç„¡æ³•é€£æ¥ã€‚"

        # G. è™•ç† ç´”æ–‡å­—
        elif file_type in ['txt', 'md']:
            text = uploaded_file.read().decode("utf-8")
            
    except Exception as e:
        return f"è®€å–æª”æ¡ˆéŒ¯èª¤ ({file_type}): {str(e)}"
        
    return text

# --- 4. å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ‡­ğŸ‡° DSE å‚™æˆ°ä¸­å¿ƒ")
    st.caption("æ”¯æ´: PDF, Word, PPT, Excel, åœ–ç‰‡, è²éŸ³")
    st.divider()
    subject = st.selectbox("ç§‘ç›®", ["Biology", "Chemistry", "Economics", "Chinese", "English", "History", "Maths"])
    
# --- 5. ä¸»åŠŸèƒ½å€ ---
tab_factory, tab_study = st.tabs(["ğŸ› ï¸ æ­¥é©Ÿä¸€ï¼šè¬èƒ½è³‡æ–™æ¸…æ´—", "ğŸ“ æ­¥é©ŸäºŒï¼šæ™ºèƒ½æº«ç¿’å®¤"])

# ==========================================
# TAB 1: è³‡æ–™æ¸…æ´— (æ”¯æ´ OCR, STT, Pandas)
# ==========================================
with tab_factory:
    st.header(f"ğŸ§¹ {subject} - å¤šåª’é«”è³‡æ–™è™•ç†å·¥å» ")
    st.info("æ”¯æ´æª”æ¡ˆï¼šPDF, Word, PPT, Excel, CSV, åœ–ç‰‡ (JPG/PNG), éŒ„éŸ³ (MP3/WAV)")
    
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³ä»»ä½•æ•™ææª”æ¡ˆ", 
        type=["pdf", "docx", "pptx", "xlsx", "csv", "txt", "md", "jpg", "png", "mp3", "wav", "m4a"]
    )
    
    if uploaded_file:
        with st.spinner("æ­£åœ¨è®€å–æª”æ¡ˆå…§å®¹ (åœ–ç‰‡/è²éŸ³å¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“)..."):
            raw_text = extract_text_from_file(uploaded_file)
        
        # æª¢æŸ¥æ˜¯å¦è®€å–æˆåŠŸ
        if str(raw_text).startswith("è®€å–æª”æ¡ˆéŒ¯èª¤") or not raw_text:
            st.error(f"ç„¡æ³•æå–å…§å®¹ï¼š{raw_text}")
        else:
            word_count = len(str(raw_text))
            st.success(f"âœ… æˆåŠŸæå–å…§å®¹ï¼å…± {word_count} å­—ã€‚")
            with st.expander("é è¦½æå–çš„åŸå§‹æ–‡å­—"):
                st.text(raw_text[:2000] + "..." if word_count > 2000 else raw_text)
            
            if st.button("ğŸš€ äº¤çµ¦ DeepSeek æ•´ç†é‡é»"):
                with st.spinner("DeepSeek æ­£åœ¨åˆ†æä¸¦æ•´ç†ç­†è¨˜..."):
                    # æ ¹æ“šæª”æ¡ˆé¡å‹å¾®èª¿ Prompt
                    clean_prompt = f"""
                    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ DSE {subject} å°å¸«ã€‚
                    è«‹è™•ç†ä»¥ä¸‹åŸå§‹æ–‡æœ¬ (å¯èƒ½ä¾†è‡ªåœ–ç‰‡ OCRã€éŒ„éŸ³è½‰éŒ„æˆ– Excel è¡¨æ ¼)ï¼Œæ•´ç†ç‚ºé«˜å“è³ªçš„ Markdown ç­†è¨˜ã€‚
                    
                    åŸå§‹æ–‡æœ¬ï¼š
                    {raw_text[:15000]} 
                    
                    è¦æ±‚ï¼š
                    1. ã€ä¿®æ­£éŒ¯èª¤ã€‘ï¼šå¦‚æœæ˜¯ OCR æˆ–èªéŸ³è½‰éŒ„ï¼Œè«‹è‡ªå‹•ä¿®æ­£æ˜é¡¯çš„éŒ¯å­—æˆ–èªæ„ä¸é€šè™•ã€‚
                    2. ã€çµæ§‹åŒ–ã€‘ï¼šæŒ‰èª²é¡Œåˆ†é¡ï¼Œå¦‚æœæ˜¯è¡¨æ ¼æ•¸æ“šï¼Œè«‹æ•´ç†ç‚ºåˆ†æçµè«–ã€‚
                    3. ã€ç²¾ç…‰ã€‘ï¼šä¿ç•™ DSE è€ƒè©¦é‡é» (Keywords)ã€‚
                    """
                    
                    try:
                        response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[{"role": "user", "content": clean_prompt}]
                        )
                        cleaned_content = response.choices[0].message.content
                        
                        st.subheader("ğŸ“ æ•´ç†å¾Œçš„ç­†è¨˜")
                        st.text_area("Result", cleaned_content, height=400)
                        
                        file_name = f"{subject}_Cleaned_Notes.txt"
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰ç­†è¨˜ (.txt) -> ç”¨æ–¼ NotebookLM",
                            data=cleaned_content,
                            file_name=file_name,
                            mime="text/plain"
                        )
                    except Exception as e:
                        st.error(f"API å‘¼å«éŒ¯èª¤: {e}")

# ==========================================
# TAB 2: æº«ç¿’å®¤ (é‚è¼¯ä¿æŒä¸è®Š)
# ==========================================
with tab_study:
    st.header(f"ğŸ“ {subject} - è¡åˆºæ¨¡å¼")
    
    col_input, col_main = st.columns([1, 2])
    with col_input:
        st.markdown("### è¼‰å…¥è³‡æº")
        notes_file = st.file_uploader("ä¸Šå‚³æ¸…æ´—å¾Œçš„ç­†è¨˜ (.txt)", type=["txt", "md", "docx"], key="notes")
        audio_file = st.file_uploader("ä¸Šå‚³ NotebookLM éŸ³æª” (.mp3)", type=["mp3", "wav"], key="audio")
        
        notes_text = ""
        if notes_file:
             notes_text = extract_text_from_file(notes_file)
    
    with col_main:
        if not notes_text:
            st.info("ğŸ‘ˆ è«‹å…ˆä¸Šå‚³ç­†è¨˜")
        else:
            sub_tab1, sub_tab2 = st.tabs(["ğŸ’¬ å°å¸«å•ç­”", "âœï¸ æ¨¡æ“¬è©¦å·"])
            
            with sub_tab1:
                st.subheader("AI å°å¸«")
                if "messages" not in st.session_state:
                    st.session_state.messages = []
                for msg in st.session_state.messages:
                    st.chat_message(msg["role"]).write(msg["content"])
                
                if user_input := st.chat_input("è¼¸å…¥å•é¡Œ..."):
                    st.session_state.messages.append({"role": "user", "content": user_input})
                    st.chat_message("user").write(user_input)
                    with st.chat_message("assistant"):
                        rag_prompt = f"ä½ æ˜¯ DSE å°å¸«ã€‚æ ¹æ“šç­†è¨˜å›ç­” (å»£æ±è©±)ï¼š\n{notes_text[:10000]}"
                        stream = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[
                                {"role": "system", "content": rag_prompt},
                                {"role": "user", "content": user_input}
                            ],
                            stream=True
                        )
                        response = st.write_stream(stream)
                    st.session_state.messages.append({"role": "assistant", "content": response})

            with sub_tab2:
                if st.button("ç”Ÿæˆé¡Œç›®"):
                     with st.spinner("å‡ºå·ä¸­..."):
                        res = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[{"role": "user", "content": f"æ ¹æ“šç­†è¨˜å‡º DSE é¡Œç›®ï¼š{notes_text[:5000]}"}]
                        )
                        st.markdown(res.choices[0].message.content)                    """
                    
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[{"role": "user", "content": clean_prompt}]
                    )
                    cleaned_content = response.choices[0].message.content
                    
                    # é¡¯ç¤ºçµæœèˆ‡ä¸‹è¼‰
                    st.subheader("ğŸ“ ç­†è¨˜é è¦½")
                    st.text_area("Result", cleaned_content, height=300)
                    
                    file_name = f"{subject}_Cleaned_Notes.txt"
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ .txt æª”æ¡ˆ (ç”¨æ–¼ NotebookLM)",
                        data=cleaned_content,
                        file_name=file_name,
                        mime="text/plain"
                    )
                    st.success("âœ… å®Œæˆï¼è«‹å°‡æ­¤æª”æ¡ˆä¸Šå‚³è‡³ NotebookLM ç”Ÿæˆ Audioã€‚")
                    
        except Exception as e:
            st.error(f"è®€å– PDF æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# ==========================================
# TAB 2: æ™ºèƒ½æº«ç¿’å®¤ (Study Room)
# ==========================================
with tab_study:
    st.header(f"ğŸ“ {subject} - è¡åˆºæ¨¡å¼")
    
    col_input, col_main = st.columns([1, 2])
    
    with col_input:
        st.markdown("### 1. è¼‰å…¥è³‡æº")
        notes_file = st.file_uploader("ä¸Šå‚³æ¸…æ´—å¾Œçš„ç­†è¨˜ (.txt)", type=["txt", "md"], key="notes")
        audio_file = st.file_uploader("ä¸Šå‚³ NotebookLM éŸ³æª” (.mp3)", type=["mp3", "wav"], key="audio")
        
        notes_text = ""
        if notes_file:
            notes_text = notes_file.read().decode("utf-8")
    
    with col_main:
        if not notes_text:
            st.info("ğŸ‘ˆ è«‹å…ˆåœ¨å·¦å´ä¸Šå‚³è³‡æº (æ­¥é©Ÿä¸€ç”¢å‡ºçš„ TXT + NotebookLM çš„ MP3)")
        else:
            # === åŠŸèƒ½åˆ†é  ===
            sub_tab1, sub_tab2, sub_tab3 = st.tabs(["ğŸ§ è½è¦ºå­¸ç¿’", "ğŸ’¬ å°å¸«å•ç­”", "âœï¸ æ¨¡æ“¬è©¦å·"])
            
            # --- è½è¦ºå­¸ç¿’ ---
            with sub_tab1:
                st.subheader("NotebookLM Podcast")
                if audio_file:
                    st.audio(audio_file)
                else:
                    st.warning("æœªä¸Šå‚³éŸ³é »ï¼Œå»ºè­°é…åˆ NotebookLM ä½¿ç”¨ä»¥é”æœ€ä½³æ•ˆæœã€‚")
                
                with st.expander("æŸ¥çœ‹å®Œæ•´ç­†è¨˜å…§å®¹"):
                    st.markdown(notes_text)

            # --- å°å¸«å•ç­” ---
            with sub_tab2:
                st.subheader("AI å°å¸« (DeepSeek)")
                if "messages" not in st.session_state:
                    st.session_state.messages = []

                for msg in st.session_state.messages:
                    st.chat_message(msg["role"]).write(msg["content"])

                if user_input := st.chat_input("e.g. ç”¨å»£æ±è©±è§£é‡‹å‘¢å€‹ Concept"):
                    st.session_state.messages.append({"role": "user", "content": user_input})
                    st.chat_message("user").write(user_input)

                    with st.chat_message("assistant"):
                        rag_prompt = f"""
                        ä½ æ˜¯ä¸€ä½ DSE {subject} å°å¸«ã€‚è«‹æ ¹æ“šä»¥ä¸‹ç­†è¨˜å›ç­”å­¸ç”Ÿå•é¡Œã€‚
                        å¿…é ˆä½¿ç”¨ã€å»£æ±è©±ã€‘ã€‚
                        ç­†è¨˜å…§å®¹ï¼š{notes_text[:12000]}
                        """
                        stream = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[
                                {"role": "system", "content": rag_prompt},
                                {"role": "user", "content": user_input}
                            ],
                            stream=True
                        )
                        response = st.write_stream(stream)
                    st.session_state.messages.append({"role": "assistant", "content": response})

            # --- æ¨¡æ“¬è©¦å· ---
            with sub_tab3:
                st.subheader("DSE é¡Œç›®ç”Ÿæˆå™¨")
                diff = st.select_slider("é›£åº¦", options=["Level 2", "Level 4", "Level 5**"])
                if st.button("ç”Ÿæˆé¡Œç›®"):
                    with st.spinner("å‡ºå·ä¸­..."):
                        q_prompt = f"""
                        æ ¹æ“šç­†è¨˜ï¼Œè¨­è¨ˆä¸€æ¢ {subject} {diff} çš„é¡Œç›® (MC æˆ– LQ)ã€‚
                        é™„å¸¶è©³ç´° Marking Schemeã€‚
                        ç­†è¨˜ï¼š{notes_text[:5000]}
                        """
                        res = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[{"role": "user", "content": q_prompt}]
                        )
                        st.markdown(res.choices[0].message.content)
