import streamlit as st
from openai import OpenAI
from pinecone import Pinecone
from sentence_transformers import SentenceTransformer
import datetime
import uuid
import time

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="DSE æ™ºèƒ½æ¸©ç¿’ç³»çµ± (Vector Cloudç‰ˆ)", 
    layout="wide", 
    page_icon="ğŸ‡­ğŸ‡°",
    initial_sidebar_state="expanded"
)

# --- 2. åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å‹ (ä½¿ç”¨ Cache åŠ é€Ÿ) ---
@st.cache_resource
def init_embedding_model():
    # ä½¿ç”¨è¼•é‡ç´šã€å…è²»çš„æ¨¡å‹ (384ç¶­)
    return SentenceTransformer('all-MiniLM-L6-v2')

@st.cache_resource
def init_pinecone(api_key):
    return Pinecone(api_key=api_key)

# è¼‰å…¥æ¨¡å‹ (åªæœƒåŸ·è¡Œä¸€æ¬¡)
with st.spinner("æ­£åœ¨é€£æ¥é›²ç«¯å¤§è…¦... (é¦–æ¬¡è¼‰å…¥éœ€æ™‚)"):
    embed_model = init_embedding_model()

# --- 3. API Key è¨­å®š ---
deepseek_key = st.secrets.get("DEEPSEEK_API_KEY") or st.sidebar.text_input("DeepSeek Key", type="password")
pinecone_key = st.secrets.get("PINECONE_API_KEY") or st.sidebar.text_input("Pinecone Key", type="password")

client = None
if deepseek_key:
    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")

pc = None
index = None
if pinecone_key:
    pc = init_pinecone(pinecone_key)
    # é€£æ¥åˆ°ä½ çš„ Index (åç¨±å¿…é ˆèˆ‡ Pinecone å¾Œå°ä¸€è‡´)
    index_name = "dse-memory" 
    index = pc.Index(index_name)

# --- 4. å‘é‡å„²å­˜å‡½æ•¸ (Upsert) ---
def save_to_vector_db(subject, question, answer, note_source="AI ç”Ÿæˆ"):
    if not index:
        st.error("æœªé€£æ¥ Pinecone è³‡æ–™åº«")
        return

    # 1. æº–å‚™æ–‡å­—è³‡æ–™
    text_to_embed = f"{subject}: {question}" # å°‡ç§‘ç›®å’Œå•é¡Œæ··åˆè½‰å‘é‡
    
    # 2. è½‰ç‚ºå‘é‡ (Embedding)
    vector = embed_model.encode(text_to_embed).tolist()
    
    # 3. æº–å‚™ Metadata (é€™æ˜¯æˆ‘å€‘è¦è®€å–çš„æ–‡å­—å…§å®¹)
    metadata = {
        "subject": subject,
        "question": question,
        "answer": answer,
        "source": note_source,
        "date": datetime.datetime.now().strftime("%Y-%m-%d"),
        "timestamp": time.time() # ç”¨æ–¼æ’åº
    }
    
    # 4. ä¸Šå‚³åˆ° Pinecone (ID ä½¿ç”¨ UUID)
    unique_id = str(uuid.uuid4())
    index.upsert(vectors=[(unique_id, vector, metadata)])
    st.toast(f"â˜ï¸ å·²å°‡é¡Œç›®æ°¸ä¹…å„²å­˜è‡³é›²ç«¯ï¼", icon="âœ…")

# --- 5. å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ‡­ğŸ‡° DSE é›²ç«¯å‚™æˆ°")
    st.caption("DeepSeek x Pinecone Vector DB")
    st.divider()
    subject = st.selectbox("ç•¶å‰ç§‘ç›®", ["Biology", "Chemistry", "Economics", "Chinese", "English", "History", "Maths", "Liberal Studies"])
    
    st.success("ğŸŸ¢ é›²ç«¯è¨˜æ†¶å·²é€£ç·š")
    st.info("ä½ çš„éŒ¯é¡Œç¾åœ¨æœƒè‡ªå‹•åŒæ­¥åˆ°é›²ç«¯è³‡æ–™åº«ï¼Œç„¡éœ€æ‰‹å‹•å­˜æª”ã€‚")

# --- 6. ä¸»åŠŸèƒ½å€ ---
tab_factory, tab_study, tab_memory = st.tabs(["ğŸ­ è³‡æ–™æ¸…æ´—", "ğŸ“ æ™ºèƒ½æº«ç¿’", "ğŸ§  é›²ç«¯è¨˜æ†¶ (Vector)"])

# ==========================================
# TAB 1: è³‡æ–™æ¸…æ´— (ç¶­æŒä¸è®Š)
# ==========================================
with tab_factory:
    st.header(f"ğŸš€ {subject} - è³‡æ–™æ¸…æ´—")
    col1, col2 = st.columns([1, 1])
    with col1:
        st.subheader("1. è¤‡è£½æŒ‡ä»¤")
        prompt_text = f"""
        (è«‹ä¸Šå‚³ PDF/åœ–ç‰‡)
        ä½ æ˜¯ä¸€ä½ DSE {subject} ç·¨è¼¯ã€‚è«‹å°‡æ–‡ä»¶æ•´ç†ç‚º Markdown ç­†è¨˜ã€‚
        è¦æ±‚ï¼šå»é™¤é›œè¨Šã€æŒ‰èª²é¡Œåˆ†é¡ã€ä¿ç•™ Keywordsã€é¡Œç›®æ•´ç†ç‚º Q&Aã€‚
        """
        st.code(prompt_text, language="text")
        st.link_button("ğŸ”— å‰å¾€ DeepSeek å®˜ç¶²", "https://chat.deepseek.com", type="primary")

    with col2:
        st.subheader("2. å‚™ä»½å­˜æª”")
        with st.form("save_file"):
            txt = st.text_area("è²¼ä¸Šå…§å®¹...", height=200)
            if st.form_submit_button("ğŸ’¾ ä¸‹è¼‰") and txt:
                st.download_button("ğŸ“¥ ä¸‹è¼‰ .txt", txt, f"{subject}_Notes.txt")

# ==========================================
# TAB 2: æ™ºèƒ½æº«ç¿’ (åŠ å…¥å‘é‡å„²å­˜)
# ==========================================
with tab_study:
    st.header(f"ğŸ“ {subject} - è¡åˆºæ¨¡å¼")
    col_input, col_main = st.columns([1, 2])
    
    with col_input:
        input_method = st.radio("ä¾†æº", ["ğŸ“‚ ä¸Šå‚³", "ğŸ“‹ è²¼ä¸Š"], horizontal=True)
        notes_text = ""
        if input_method == "ğŸ“‹ è²¼ä¸Š":
            notes_text = st.text_area("è²¼ä¸Šç­†è¨˜ï¼š", height=300)
        else:
            files = st.file_uploader("ä¸Šå‚³ .txt", type=["txt"], accept_multiple_files=True)
            if files:
                for f in files: notes_text += f"\n--- {f.name} ---\n{f.read().decode('utf-8')}"
        audio = st.file_uploader("NotebookLM éŸ³æª”", type=["mp3"])

    with col_main:
        if not notes_text:
            st.info("ğŸ‘ˆ è«‹å…ˆè¼‰å…¥ç­†è¨˜")
        else:
            if not client: st.error("ç¼º API Key"); st.stop()

            sub1, sub2, sub3 = st.tabs(["ğŸ§ è½æ›¸", "ğŸ’¬ å•ç­”", "âœï¸ æ¨¡æ“¬å·"])
            
            with sub1:
                if audio: st.audio(audio)
                with st.expander("ç­†è¨˜å…§å®¹"): st.markdown(notes_text)

            with sub2: # å•ç­”
                if "messages" not in st.session_state: st.session_state.messages = []
                for m in st.session_state.messages: st.chat_message(m["role"]).write(m["content"])
                
                if q := st.chat_input("è¼¸å…¥å•é¡Œ..."):
                    st.session_state.messages.append({"role": "user", "content": q})
                    st.chat_message("user").write(q)
                    with st.chat_message("assistant"):
                        rag = f"ä½ ä¿‚ DSE {subject} å°å¸«ã€‚æ ¹æ“šç­†è¨˜ç”¨å»£æ±è©±ç­”ï¼š\n{notes_text[:12000]}"
                        ans = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"system","content":rag},{"role":"user","content":q}]).choices[0].message.content
                        st.markdown(ans)
                        # å‘é‡å„²å­˜æŒ‰éˆ•
                        st.button("â­ å­˜å…¥é›²ç«¯è¨˜æ†¶", key=f"save_{len(st.session_state.messages)}", on_click=save_to_vector_db, args=(subject, q, ans))
                    st.session_state.messages.append({"role": "assistant", "content": ans})

            with sub3: # å‡ºå·
                c1, c2, c3 = st.columns([2,2,1])
                with c1: diff = st.select_slider("é›£åº¦", ["L3","L4","L5","L5**"], "L4")
                with c2: qt = st.radio("é¡Œå‹", ["MC","LQ"], horizontal=True)
                with c3: num = st.number_input("æ•¸é‡", 1, 10, 1)
                
                if st.button("ğŸš€ ç”Ÿæˆé¡Œç›®"):
                    prompt = f"DSE {subject} å‡ºå·å“¡ã€‚å‡º {num} æ¢ {diff} {qt}ã€‚å…ˆåˆ—é¡Œç›®ï¼Œæ’å…¥ `<<<SPLIT>>>`ï¼Œå†åˆ—ç­”æ¡ˆã€‚MC å‚ç›´åˆ†è¡Œã€‚ç­†è¨˜ï¼š{notes_text[:6000]}"
                    res = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}]).choices[0].message.content
                    q_part, a_part = res.split("<<<SPLIT>>>") if "<<<SPLIT>>>" in res else (res, "è¦‹ä¸Šæ–¹")
                    st.session_state['quiz'] = {"q": q_part, "a": a_part}

                if 'quiz' in st.session_state:
                    st.markdown("### ğŸ“ è©¦é¡Œ"); st.markdown(st.session_state['quiz']['q'])
                    with st.expander("ğŸ” ç­”æ¡ˆ"): st.markdown(st.session_state['quiz']['a'])
                    # å‘é‡å„²å­˜æŒ‰éˆ•
                    st.button("â­ å­˜å…¥é›²ç«¯è¨˜æ†¶", key="save_quiz", on_click=save_to_vector_db, args=(subject, st.session_state['quiz']['q'], st.session_state['quiz']['a'], "æ¨¡æ“¬é¡Œ"))

# ==========================================
# TAB 3: ğŸ§  é›²ç«¯è¨˜æ†¶ (Vector Space)
# ==========================================
with tab_memory:
    st.header("ğŸ§  é›²ç«¯éŒ¯é¡Œåº« (Vector Search)")
    st.caption("æ‰€æœ‰è³‡æ–™å·²å„²å­˜åœ¨ Pinecone é›²ç«¯ï¼Œç„¡éœ€æ‰‹å‹•å­˜æª”ã€‚æ”¯æ´èªæ„æœå°‹ã€‚")
    
    if not index:
        st.error("è«‹å…ˆè¨­å®š Pinecone API Key")
        st.stop()

    col_search, col_filter = st.columns([3, 1])
    
    with col_search:
        # é€™æ˜¯å‘é‡æœå°‹çš„æ ¸å¿ƒï¼
        search_query = st.text_input("ğŸ” æœå°‹è¨˜æ†¶ (ä¾‹å¦‚ï¼šæœå°‹ 'å…‰åˆä½œç”¨' ç›¸é—œéŒ¯é¡Œ)", placeholder="è¼¸å…¥é—œéµå­—...")
    
    with col_filter:
        filter_subject = st.selectbox("ç§‘ç›®ç¯©é¸", ["æ‰€æœ‰ç§‘ç›®", "Biology", "Chemistry", "Economics", "History"])

    st.markdown("---")

    # åŸ·è¡Œæœå°‹æˆ–ç²å–åˆ—è¡¨
    results = []
    
    if search_query:
        # === æ¨¡å¼ A: èªæ„æœå°‹ (Semantic Search) ===
        # 1. å°‡æœå°‹è©è½‰ç‚ºå‘é‡
        query_vector = embed_model.encode(search_query).tolist()
        
        # 2. æº–å‚™éæ¿¾æ¢ä»¶ (å¦‚æœ‰)
        filter_dict = {}
        if filter_subject != "æ‰€æœ‰ç§‘ç›®":
            filter_dict = {"subject": filter_subject}
            
        # 3. å‘ Pinecone æŸ¥è©¢æœ€ç›¸ä¼¼çš„å…§å®¹
        search_res = index.query(
            vector=query_vector, 
            top_k=10, 
            include_metadata=True,
            filter=filter_dict if filter_dict else None
        )
        results = search_res['matches']
        st.success(f"ğŸ” æ‰¾åˆ° {len(results)} æ¢èˆ‡ã€Œ{search_query}ã€ç›¸é—œçš„è¨˜æ†¶")

    else:
        # === æ¨¡å¼ B: ç€è¦½æ¨¡å¼ (Browse) ===
        # ç”±æ–¼ Pinecone ä¸»è¦æ˜¯æœå°‹ç”¨çš„ï¼Œè¦ã€Œåˆ—å‡ºå…¨éƒ¨ã€æ¯”è¼ƒéº»ç…©ã€‚
        # é€™è£¡æˆ‘å€‘ç”¨ä¸€å€‹ Dummy Vector é€²è¡ŒæŸ¥è©¢ï¼Œæˆ–è€…æç¤ºç”¨æˆ¶è¼¸å…¥ã€‚
        # ç‚ºäº†å±•ç¤ºæ•ˆæœï¼Œæˆ‘å€‘ç”Ÿæˆä¸€å€‹ã€Œç©ºå‘é‡ã€ä¾†ç²å–æœ€è¿‘å­˜å…¥çš„é …ç›®
        
        # å‰µå»ºä¸€å€‹å…¨ 0 çš„å‘é‡ (é•·åº¦ 384) ä½œç‚º dummy
        dummy_vector = [0.0] * 384 
        
        filter_dict = {}
        if filter_subject != "æ‰€æœ‰ç§‘ç›®":
            filter_dict = {"subject": filter_subject}
            
        # ç²å–æœ€è¿‘çš„ 20 æ¢
        search_res = index.query(
            vector=dummy_vector, 
            top_k=20, 
            include_metadata=True,
            filter=filter_dict if filter_dict else None
        )
        results = search_res['matches']
        if len(results) > 0:
            st.info("ğŸ“… é¡¯ç¤ºæœ€è¿‘åŠ å…¥çš„è¨˜æ†¶ (è¼¸å…¥é—œéµå­—å¯é€²è¡Œç²¾æº–æœå°‹)")
        else:
            st.info("ğŸ“­ é›²ç«¯è¨˜æ†¶åº«æš«æ™‚æ˜¯ç©ºçš„ï¼Œå¿«å»æº«ç¿’åŠ å…¥éŒ¯é¡Œå§ï¼")

    # é¡¯ç¤ºçµæœå¡ç‰‡
    for match in results:
        data = match['metadata']
        score = match.get('score', 0)
        
        # æ¨£å¼åŒ–é¡¯ç¤º
        with st.container():
            st.markdown(f"""
            <div style="border:1px solid #eee; padding:15px; border-radius:10px; margin-bottom:10px; background-color:#fafafa;">
                <div style="display:flex; justify-content:space-between;">
                    <small style="color:#0068c9; font-weight:bold;">{data.get('subject', 'General')}</small>
                    <small style="color:grey;">é—œè¯åº¦: {score:.2f} | {data.get('date', '')}</small>
                </div>
                <div style="margin-top:5px; font-size:1.1em;"><b>Q: </b>{data.get('question')}</div>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander(f"ğŸ‘ï¸ æŸ¥çœ‹ç­”æ¡ˆ"):
                st.markdown(data.get('answer'))
                # åˆªé™¤åŠŸèƒ½æ¯”è¼ƒè¤‡é›œï¼Œé€™è£¡æš«æ™‚çœç•¥ï¼Œå› ç‚º Vector DB åˆªé™¤éœ€è¦ ID
